{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils import paths\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covid_detector.evaluate_covid19 import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation class that performs forward pass through trained models\n",
    "\"\"\"\n",
    "#%%\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import (\n",
    "    AveragePooling2D, Dense, Dropout, Flatten, Input, BatchNormalization, ReLU\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from covid_detector.utils import CLASS_MAPPINGS\n",
    "\n",
    "\n",
    "#%%\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self, split=None, modality='pocus'):\n",
    "        print(\"init\")\n",
    "        \"\"\"\n",
    "        Constructor of COVID model evaluator class.\n",
    "        \n",
    "        Arguments:\n",
    "            modality {str} -- The data modality to be used. Chose from\n",
    "                {'pocus', 'xray', 'ct'}, defaults to 'pocus'.\n",
    "        \"\"\"\n",
    "\n",
    "        if modality not in ['pocus', 'xray', 'ct']:\n",
    "            raise ValueError(f'Unknown modality provided: {modality}')\n",
    "\n",
    "        self.modality = modality\n",
    "        self.num_classes = 3 if modality == 'pocus' else 2\n",
    "        # load correct weights\n",
    "        if split is None:\n",
    "            self.weights_path = os.path.join(\n",
    "                '..', 'trained_models', modality + '.model'\n",
    "            )\n",
    "        else:\n",
    "            # This is not the best, but the last one\n",
    "            # self.weights_path = os.path.join(\n",
    "            #     '..', 'trained_models', 'fold_' + split, 'pocus_fold_' + split + '.model'\n",
    "            # )\n",
    "            #\n",
    "            # This is the best model:\n",
    "            self.weights_path = os.path.join(\n",
    "                '..', 'trained_models', 'fold_' + split, \"variables\", \"variables\"\n",
    "            )\n",
    "            print(\"Loading weights from \", self.weights_path)\n",
    "            \n",
    "        self.class_mappings = CLASS_MAPPINGS[self.modality]\n",
    "\n",
    "        # load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "        baseModel = VGG16(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            input_tensor=Input(shape=(224, 224, 3))\n",
    "        )\n",
    "\n",
    "        # construct the head of the model that will be placed on top of the\n",
    "        # the base model\n",
    "        headModel = baseModel.output\n",
    "        headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
    "        headModel = Flatten(name=\"flatten\")(headModel)\n",
    "        headModel = Dense(64)(headModel)\n",
    "        headModel = BatchNormalization()(headModel)\n",
    "        headModel = ReLU()(headModel)\n",
    "        headModel = Dropout(0.5)(headModel)\n",
    "        headModel = Dense(self.num_classes, activation=\"softmax\")(headModel)\n",
    "\n",
    "        # place the head FC model on top of the base model\n",
    "        self.model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "        # restore weights\n",
    "        try:\n",
    "            self.model.load_weights(self.weights_path)\n",
    "        except Exception:\n",
    "            raise Exception('Error in model restoring.')\n",
    "\n",
    "        print(f'Model restored. Class mappings are {self.class_mappings}')\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \"\"\"Performs a forward pass through the restored model\n",
    "\n",
    "        Arguments:\n",
    "            image {np.array} -- Input image on which prediction is performed. \n",
    "                No size requirements, but the image will be reshaped to 224 x\n",
    "                224 pixels (aspec ratio is *not* preserved, so quadratic images\n",
    "                are preferred).\n",
    "\n",
    "        Returns:\n",
    "            logits {np.array} -- Shape (self.num_classes,). Class probabilities\n",
    "                for 2 (or 3) classes.\n",
    "        \"\"\"\n",
    "\n",
    "        image = self.preprocess(image)\n",
    "        return np.squeeze(self.model.predict(image))\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        \"\"\"Apply image preprocessing pipeline\n",
    "\n",
    "        Arguments:\n",
    "            image {np.array} -- Arbitrary shape, quadratic preferred\n",
    "\n",
    "        Returns:\n",
    "            np.array -- Shape 224,224. Normalized to [0, 1].\n",
    "        \"\"\"\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = np.expand_dims(np.array(image), 0) / 255.0\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for prediction of video label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(preds, gt, vid_filenames):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \tpreds: predicted classes (1-d list of class_names or integers)\n",
    "        gt: list of same size with ground truth labels\n",
    "        vid_filenames: list of filenames\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds)\n",
    "    gt = np.asarray(gt)\n",
    "    vids = np.asarray([vid.split(\".\")[0] for vid in vid_filenames])\n",
    "    vid_preds_out = []\n",
    "    for v in np.unique(vids):\n",
    "        preds_video = preds[vids==v]\n",
    "        gt_check = np.unique(gt[vids==v])\n",
    "        assert len(gt_check)==1, \"gt must have the same label for the whole video\"\n",
    "        labs, pred_counts = np.unique(preds_video, return_counts=True)\n",
    "        # take label that is predicted most often\n",
    "        vid_pred = labs[np.argmax(pred_counts)]\n",
    "        print(\"preds for video:\", preds_video)\n",
    "        # print(v, vid_pred, gt_check[0])\n",
    "        vid_preds_out.append([v, vid_pred, gt_check[0]])\n",
    "    print(\"video accuracy (majority):\", accuracy_score([p[1] for p in vid_preds_out], [p[2] for p in vid_preds_out]))\n",
    "    return vid_preds_out\n",
    "        \n",
    "def average_certainty(preds_logits, gt, vid_filenames):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \tpreds: predicted classes (1-d list of class_names or integers)\n",
    "        gt: list of same size with ground truth labels\n",
    "        vid_filenames: list of filenames\n",
    "    \"\"\"\n",
    "    preds_logits = np.asarray(preds_logits)\n",
    "    gt = np.asarray(gt)\n",
    "    vid_preds_out = []\n",
    "    vids = np.array([vid.split(\".\")[0] for vid in vid_filenames])\n",
    "    for v in np.unique(vids):\n",
    "        preds_video_logits = preds_logits[vids==v]\n",
    "        preds_video = np.sum(preds_video_logits, axis=0)\n",
    "        print(\"preds for video:\", preds_video)\n",
    "        gt_check = np.unique(gt[vids==v])\n",
    "        assert len(gt_check)==1, \"gt must have the same label for the whole video\"\n",
    "        # take label that is predicted most often\n",
    "        vid_pred = np.argmax(preds_video)\n",
    "        print(v, vid_pred, gt_check[0])\n",
    "        vid_preds_out.append([v, vid_pred, gt_check[0]])\n",
    "    print(\"video accuracy (certainty):\", accuracy_score([p[1] for p in vid_preds_out], [p[2] for p in vid_preds_out]))\n",
    "    return vid_preds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation script for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "Loading weights from  ../trained_models/fold_1/variables/variables\n",
      "Model restored. Class mappings are ['covid', 'pneunomia', 'regular']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       1.00      0.99      1.00       111\n",
      "   pneunomia       0.96      1.00      0.98        22\n",
      "     regular       1.00      1.00      1.00        49\n",
      "\n",
      "    accuracy                           0.99       182\n",
      "   macro avg       0.99      1.00      0.99       182\n",
      "weighted avg       0.99      0.99      0.99       182\n",
      "\n",
      "preds for video: [49.459686   0.8778944  4.66241  ]\n",
      "Cov-Butterfly-COVID Lung 1 0 0\n",
      "preds for video: [0.01668004 0.88386697 0.09945303]\n",
      "Cov-C_ConvexProb_score3 1 0\n",
      "preds for video: [48.888733   0.8593776  5.251895 ]\n",
      "Cov-MSU-SkipLesions 0 0\n",
      "preds for video: [0.52138484 9.024886   2.4537296 ]\n",
      "Pneu-Atlas-pneumonia 1 1\n",
      "preds for video: [4.1147294e-05 9.9864788e+00 1.3480580e-02]\n",
      "Pneu-grep-pneumonia4 1 1\n",
      "preds for video: [ 4.2803226  1.1730975 43.546577 ]\n",
      "Reg-Butterfly 2 2\n",
      "video accuracy (certainty): 0.8333333333333334\n",
      "preds for video: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds for video: [1]\n",
      "preds for video: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds for video: [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "preds for video: [1 1 1 1 1 1 1 1 1 1]\n",
      "preds for video: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "video accuracy (majority): 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    print(\"------------- SPLIT \", i, \"-------------------\")\n",
    "    # define data input path\n",
    "    path = \"../data_pocus/cross_validation_data/split\"+str(i)\n",
    "    \n",
    "    train_labels, test_labels, test_files = [], [], []\n",
    "    train_data, test_data = [], []\n",
    "\n",
    "    # loop over the image paths (train and test)\n",
    "    for imagePath in paths.list_images(path):\n",
    "\n",
    "        # extract the class label from the filename\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "        # load the image, swap color channels, and resize it to be a fixed\n",
    "        # 224x224 pixels while ignoring aspect ratio\n",
    "        image = cv2.imread(imagePath)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # image = cv2.resize(image, (224, 224))\n",
    "\n",
    "        # update the data and labels lists, respectively\n",
    "        test_labels.append(label)\n",
    "        test_data.append(image)\n",
    "        test_files.append(imagePath.split(os.path.sep)[-1])\n",
    "\n",
    "    # build ground truth data\n",
    "    classes = [\"covid\", \"pneunomia\", \"regular\"]\n",
    "    gt_class_idx = np.array([classes.index(lab) for lab in test_labels])\n",
    "    \n",
    "    model = Evaluator(split=str(i))\n",
    "    \n",
    "    logits = np.array([model(img) for img in test_data])\n",
    "    predIdxs = np.argmax(logits, axis=1)\n",
    "    \n",
    "    print(\n",
    "    classification_report(\n",
    "        gt_class_idx, predIdxs, target_names=classes\n",
    "        )\n",
    "    )\n",
    "\n",
    "    vid_preds_certainty = average_certainty(logits, gt_class_idx, np.array(test_files))\n",
    "    vid_preds_majority = majority_vote(predIdxs, gt_class_idx, np.array(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "../trained_models/fold_0/pocus_fold_0.model\n",
      "Model restored. Class mappings are ['covid', 'pneunomia', 'regular']\n"
     ]
    }
   ],
   "source": [
    "model = Evaluator(split=str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       0.56      0.56      0.56        63\n",
      "   pneunomia       0.44      0.79      0.56        28\n",
      "     regular       0.67      0.38      0.48        48\n",
      "\n",
      "    accuracy                           0.54       139\n",
      "   macro avg       0.56      0.57      0.53       139\n",
      "weighted avg       0.57      0.54      0.53       139\n",
      "\n",
      "Cov-Atlas+(44) 1 0\n",
      "Cov-Atlas+(45) 1 0\n",
      "Cov-Atlas-+(43) 1 0\n",
      "Cov-Atlas-Day+1 2 0\n",
      "Cov-Atlas-Day+2 0 0\n",
      "Cov-Atlas-Day+3 0 0\n",
      "Cov-Atlas-Day+4 0 0\n",
      "Cov-B_ConvexProb_score1 0 0\n",
      "Pneu-grep-pneumonia2 1 1\n",
      "Reg-Atlas 0 2\n",
      "Reg-Atlas-alines 2 2\n",
      "Reg-Atlas-lungcurtain 1 2\n",
      "Reg-Youtube 0 2\n",
      "video accuracy (certainty): 0.46153846153846156\n",
      "video accuracy (majority): 0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([model(img) for img in test_data])\n",
    "predIdxs = np.argmax(logits, axis=1)\n",
    "\n",
    "print(\n",
    "classification_report(\n",
    "    gt_class_idx, predIdxs, target_names=classes\n",
    "    )\n",
    ")\n",
    "\n",
    "vid_preds_certainty = average_certainty(logits, gt_class_idx, np.array(test_files))\n",
    "vid_preds_majority = majority_vote(predIdxs, gt_class_idx, np.array(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds for video: [0.7476117 7.1902814 1.0621074]\n",
      "Cov-Atlas+(44) 1 0\n",
      "preds for video: [0.8079691 2.2369947 1.9550362]\n",
      "Cov-Atlas+(45) 1 0\n",
      "preds for video: [0.6700281 4.4929104 2.8370612]\n",
      "Cov-Atlas-+(43) 1 0\n",
      "preds for video: [0.8921366  0.14128703 5.9665766 ]\n",
      "Cov-Atlas-Day+1 2 0\n",
      "preds for video: [11.983487   1.601364   3.4151487]\n",
      "Cov-Atlas-Day+2 0 0\n",
      "preds for video: [7.294277   0.18070902 0.5250141 ]\n",
      "Cov-Atlas-Day+3 0 0\n",
      "preds for video: [7.270071   0.07357544 0.65635365]\n",
      "Cov-Atlas-Day+4 0 0\n",
      "preds for video: [0.97913533 0.01976757 0.00109702]\n",
      "Cov-B_ConvexProb_score1 0 0\n",
      "preds for video: [ 2.7778866 23.352705   1.8694102]\n",
      "Pneu-grep-pneumonia2 1 1\n",
      "preds for video: [8.20206   2.8440855 0.9538548]\n",
      "Reg-Atlas 0 2\n",
      "preds for video: [ 0.16833213  1.628948   10.202721  ]\n",
      "Reg-Atlas-alines 2 2\n",
      "preds for video: [0.85913706 5.7818565  5.3590064 ]\n",
      "Reg-Atlas-lungcurtain 1 2\n",
      "preds for video: [5.5052576 4.1001887 2.3945541]\n",
      "Reg-Youtube 0 2\n",
      "video accuracy (certainty): 0.46153846153846156\n",
      "preds for video: [1 1 1 1 1 1 1 1 1]\n",
      "preds for video: [1 2 2 1 1]\n",
      "preds for video: [1 1 2 1 1 1 1 1]\n",
      "preds for video: [2 2 2 0 2 2 2]\n",
      "preds for video: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds for video: [0 0 0 0 0 0 0 0]\n",
      "preds for video: [0 0 0 0 0 0 0 0]\n",
      "preds for video: [0]\n",
      "preds for video: [1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1]\n",
      "preds for video: [0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "preds for video: [2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds for video: [1 2 1 1 2 2 2 2 1 1 1 2]\n",
      "preds for video: [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "video accuracy (majority): 0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "vid_preds_certainty = average_certainty(logits, gt_class_idx, np.array(test_files))\n",
    "vid_preds_majority = majority_vote(predIdxs, gt_class_idx, np.array(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "../trained_models/fold_0/variables/variables\n",
      "Model restored. Class mappings are ['covid', 'pneunomia', 'regular']\n"
     ]
    }
   ],
   "source": [
    "model2 = Evaluator(split=str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       0.70      0.56      0.62        63\n",
      "   pneunomia       0.71      0.79      0.75        28\n",
      "     regular       0.67      0.81      0.74        48\n",
      "\n",
      "    accuracy                           0.69       139\n",
      "   macro avg       0.69      0.72      0.70       139\n",
      "weighted avg       0.69      0.69      0.69       139\n",
      "\n",
      "preds for video: [0.41692764 5.862566   2.720506  ]\n",
      "Cov-Atlas+(44) 1 0\n",
      "preds for video: [0.2946806 1.1493942 3.5559251]\n",
      "Cov-Atlas+(45) 2 0\n",
      "preds for video: [0.2536777 2.318747  5.4275756]\n",
      "Cov-Atlas-+(43) 2 0\n",
      "preds for video: [1.0876949  0.30086467 5.61144   ]\n",
      "Cov-Atlas-Day+1 2 0\n",
      "preds for video: [11.281307   2.2195392  3.4991531]\n",
      "Cov-Atlas-Day+2 0 0\n",
      "preds for video: [6.9004602  0.37701795 0.72252214]\n",
      "Cov-Atlas-Day+3 0 0\n",
      "preds for video: [7.207155   0.11220858 0.68063533]\n",
      "Cov-Atlas-Day+4 0 0\n",
      "preds for video: [0.9263738  0.06457515 0.0090511 ]\n",
      "Cov-B_ConvexProb_score1 0 0\n",
      "preds for video: [ 3.1745064 23.195557   1.6299381]\n",
      "Pneu-grep-pneumonia2 1 1\n",
      "preds for video: [5.6316576 1.944488  4.4238553]\n",
      "Reg-Atlas 0 2\n",
      "preds for video: [ 0.09701819  1.1377169  10.765265  ]\n",
      "Reg-Atlas-alines 2 2\n",
      "preds for video: [0.48782772 2.7532372  8.758935  ]\n",
      "Reg-Atlas-lungcurtain 2 2\n",
      "preds for video: [1.9299976 2.7541149 7.3158875]\n",
      "Reg-Youtube 2 2\n",
      "video accuracy (certainty): 0.6153846153846154\n",
      "preds for video: [1 1 1 1 1 1 1 1 1]\n",
      "preds for video: [2 2 2 2 2]\n",
      "preds for video: [2 2 2 2 2 2 2 2]\n",
      "preds for video: [2 2 2 0 2 2 2]\n",
      "preds for video: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "preds for video: [0 0 0 0 0 0 0 0]\n",
      "preds for video: [0 0 0 0 0 0 0 0]\n",
      "preds for video: [0]\n",
      "preds for video: [1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1]\n",
      "preds for video: [0 0 2 2 2 2 0 0 2 0 0 0]\n",
      "preds for video: [2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds for video: [2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "preds for video: [2 2 0 2 2 2 2 2 0 2 2 2]\n",
      "video accuracy (majority): 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([model2(img) for img in test_data])\n",
    "predIdxs = np.argmax(logits, axis=1)\n",
    "\n",
    "print(\n",
    "classification_report(\n",
    "    gt_class_idx, predIdxs, target_names=classes\n",
    "    )\n",
    ")\n",
    "\n",
    "vid_preds_certainty = average_certainty(logits, gt_class_idx, np.array(test_files))\n",
    "vid_preds_majority = majority_vote(predIdxs, gt_class_idx, np.array(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
