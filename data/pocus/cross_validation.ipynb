{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"cleaned_data_images\"\n",
    "CROSS_VAL_DIR = \"cross_validation_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make splits of approximately equal test size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cov-Butterfly-COVID Lung 2', 'Cov-Butterfly-Confluent B lines_Example 2', 'Cov-clarius', 'Cov-clarius3', 'Cov-grep-7453'] 120\n",
      "['Cov-Butterfly-Irregular Pleura with Confluent B-lines', 'Cov-Atlas+(45)', 'Cov-Butterfly-Consolidation with Air Bronc', 'Cov-Butterfly-Irregular Pleura with Multip', 'Cov-grep-7510', 'Cov-grep-7511', 'Cov-Atlas-Day+3', 'Cov-Butterfly-Irregular Pleural Line'] 113\n",
      "['Cov-grep-7505', 'Cov-grep-7543', 'Cov-grep-7525', 'Cov-Butterfly-Consolidation', 'Cov-Atlas-Day+1', 'Cov-Butterfly-Coalescing B lines', 'Cov-Butterfly-COVID Lung 1', 'Cov-Butterfly-Subpleural Basal Consolidation_Example 2', 'Cov-Butterfly-Irregular Pleural Line_Example 2', 'Cov-Butterfly-Irregular Pleura with Trace Effusion', 'Cov-Atlas-suspectedCovid', 'Cov-Butterfly-COVID Skip Lesion', 'Cov-Butterfly-Consolidation_Example 3', 'Cov-Atlas-+(43)'] 183\n",
      "['Cov-grepmed-blines-pocus-', 'Cov-Butterfly-Subpleural Basal Consolidation', 'Cov-Butterfly-Patchy B lines with Sparing', 'Cov-grep-7507', 'Cov-Butterfly-Consolidation_Example 2', 'Cov-Butterfly-Consolidation_Example 5', 'Cov-Butterfly-Irregular Pleura and Coalescent B-lines'] 128\n",
      "['Cov-grepmed3', 'Cov-grepmed2', 'Cov-Atlas+(44)', 'Cov-Atlas-Day+4', 'Cov-Atlas-Day+2'] 110\n",
      "['Pneu-Atlas-pneumonia-AirBronch', 'Pneu-Atlas-pneumonia2', 'Pneu-grep-bacterial-hepatization-clinical'] 58\n",
      "['Pneu-grep-pneumonia2_1', 'Pneu-grep-shredsign-consolidation'] 60\n",
      "['Pneu-grep-pneumonia4', 'Pneu-grep-pneumonia1', 'Pneu-grep-pulmonary-pneumonia', 'Pneu-Atlas-pneumonia'] 71\n",
      "['pneu-everyday', 'pneu-gred-7', 'Pneu-grep-pneumonia3'] 42\n",
      "['pneu-gred-6', 'pneu-radiopaeda'] 46\n",
      "['Reg-Atlas-alines', 'Reg-Atlas-lungcurtain'] 40\n",
      "['Reg-Butterfly-2', 'Reg-NormalLungs'] 31\n",
      "['Reg-Grep-Alines', 'Reg-Grep-Normal'] 22\n",
      "['Reg-Youtube', 'Reg-Atlas'] 37\n",
      "['Reg-bcpocus', 'Reg-nephropocus', 'Reg-Butterfly'] 42\n"
     ]
    }
   ],
   "source": [
    "split_test = [{} for _ in range(SPLIT)]\n",
    "\n",
    "num_scans_per_video = []\n",
    "\n",
    "for modality in [\"covid\", \"pneumonia\", \"regular\"]:\n",
    "    p_vids = []\n",
    "    p_fn = []\n",
    "    # for traintest in [\"train\", \"test\"]:\n",
    "    for cov_data in os.listdir(os.path.join(base_dir, modality)):\n",
    "        if cov_data[0]==\".\":\n",
    "            continue\n",
    "        p_fn.append(cov_data)\n",
    "        p_vids.append(cov_data.split(\".\")[0])\n",
    "    vid_names, count1 = np.unique(p_vids, return_counts=True)\n",
    "    count = count1.copy()\n",
    "    name_list = [[v] for v in vid_names]\n",
    "    # for i in range(len(vid_names)):\n",
    "    #     print(vid_names[i], count1[i])\n",
    "        \n",
    "\n",
    "    # TODO: stattdessen mit opencv the number of frames holen\n",
    "\n",
    "    # summarize to number of split (always merge the ones with smallest count)\n",
    "    while len(count)>SPLIT:\n",
    "        arg_inds = np.argsort(count)\n",
    "        # merge smallest counts\n",
    "        count[arg_inds[0]] = count[arg_inds[0]] + count[arg_inds[1]]\n",
    "        count = np.delete(count, arg_inds[1])\n",
    "        # merge video names in smallest counts\n",
    "        name_list[arg_inds[0]].extend(name_list[arg_inds[1]])\n",
    "        del name_list[arg_inds[1]]\n",
    "    for i in range(len(name_list)):\n",
    "        print(name_list[i], count[i])\n",
    "        num_scans_per_video.append(count1[i])\n",
    "    \n",
    "    # get filenames instead of video names\n",
    "    f_list = [[] for _ in range(SPLIT)]\n",
    "    for j in range(SPLIT):\n",
    "        # iterate over videos for this split\n",
    "        fn_list = []\n",
    "        for vid in name_list[j]:\n",
    "            fn_list.extend(np.array(p_fn)[np.array(p_vids)==vid])\n",
    "        f_list[j] = fn_list\n",
    "    \n",
    "    # add to overall split list\n",
    "    for j in range(SPLIT):\n",
    "        split_test[j][modality] = f_list[j]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy data from all data in cross_val directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0332412515993425"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(num_scans_per_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_ind in range(SPLIT):\n",
    "    # make directory for this split\n",
    "    split_path = os.path.join(CROSS_VAL_DIR, \"split\"+str(split_ind))\n",
    "    if not os.path.exists(split_path):\n",
    "        os.makedirs(split_path)\n",
    "    # add each data type\n",
    "    for modality in split_test[split_ind].keys():\n",
    "        # make directory for each modality\n",
    "        mod_path = os.path.join(split_path, modality)\n",
    "        if not os.path.exists(mod_path):\n",
    "            os.makedirs(mod_path)\n",
    "        # copy all files\n",
    "        mod_split_files = split_test[split_ind][modality]\n",
    "        for fname in mod_split_files:\n",
    "            shutil.copy(os.path.join(base_dir, modality, fname), mod_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- SPLIT  0 -------------------\n",
      "train ['Cov-Butterfly-COVID Lung 1' 'Cov-Butterfly-COVID Lung 2'\n",
      " 'Cov-Butterfly-COVID Skip Lesion' 'Cov-MSU-COVID Lung 2-Blines'\n",
      " 'Cov-MSU-SkipLesions' 'Cov-clarius' 'Cov-grepmed-blines-pocus-'\n",
      " 'Cov-grepmed2' 'Cov-grepmed3' 'Pneu-Atlas-pneumonia'\n",
      " 'Pneu-Atlas-pneumonia-AirBronch' 'Pneu-Atlas-pneumonia2'\n",
      " 'Pneu-grep-pneumonia1' 'Pneu-grep-pneumonia3' 'Pneu-grep-pneumonia4'\n",
      " 'Reg-Butterfly' 'Reg-Grep-Alines' 'Reg-Grep-Normal' 'Reg-NormalLungs'\n",
      " 'Reg-Youtube-Video_902_Lung_POCUS'\n",
      " 'Reg-Youtube-Video_902_Lung_POCUS-left'\n",
      " 'Reg-Youtube_Video_29_Lung_POCUS_left'\n",
      " 'Reg-Youtube_Video_29_Lung_POCUS_right' 'Reg-bcpocus' 'Reg-nephropocus'\n",
      " 'pneu-everyday' 'pneu-gred-6' 'pneu-gred-7' 'pneu-radiopaeda']\n",
      "test ['Cov-Atlas+(44)' 'Cov-Atlas+(45)' 'Cov-Atlas-+(43)' 'Cov-Atlas-Day+1'\n",
      " 'Cov-Atlas-Day+2' 'Cov-Atlas-Day+3' 'Cov-Atlas-Day+4'\n",
      " 'Cov-B_ConvexProb_score1' 'Cov-C_ConvexProb_score3'\n",
      " 'Cov-C_Convex_Prob_score2' 'Cov-D_Convex_Prob_score3'\n",
      " 'Pneu-grep-pneumonia2' 'Reg-Atlas' 'Reg-Atlas-alines'\n",
      " 'Reg-Atlas-lungcurtain' 'Reg-Youtube']\n",
      "45\n",
      "-------------- SPLIT  1 -------------------\n",
      "train ['Cov-Atlas+(44)' 'Cov-Atlas+(45)' 'Cov-Atlas-+(43)' 'Cov-Atlas-Day+1'\n",
      " 'Cov-Atlas-Day+2' 'Cov-Atlas-Day+3' 'Cov-Atlas-Day+4'\n",
      " 'Cov-B_ConvexProb_score1' 'Cov-Butterfly-COVID Lung 2'\n",
      " 'Cov-Butterfly-COVID Skip Lesion' 'Cov-C_ConvexProb_score3'\n",
      " 'Cov-C_Convex_Prob_score2' 'Cov-D_Convex_Prob_score3'\n",
      " 'Cov-MSU-COVID Lung 2-Blines' 'Cov-clarius' 'Cov-grepmed-blines-pocus-'\n",
      " 'Cov-grepmed2' 'Cov-grepmed3' 'Pneu-Atlas-pneumonia-AirBronch'\n",
      " 'Pneu-Atlas-pneumonia2' 'Pneu-grep-pneumonia1' 'Pneu-grep-pneumonia2'\n",
      " 'Pneu-grep-pneumonia3' 'Reg-Atlas' 'Reg-Atlas-alines'\n",
      " 'Reg-Atlas-lungcurtain' 'Reg-Grep-Alines' 'Reg-Grep-Normal'\n",
      " 'Reg-NormalLungs' 'Reg-Youtube' 'Reg-Youtube-Video_902_Lung_POCUS'\n",
      " 'Reg-Youtube-Video_902_Lung_POCUS-left'\n",
      " 'Reg-Youtube_Video_29_Lung_POCUS_left'\n",
      " 'Reg-Youtube_Video_29_Lung_POCUS_right' 'Reg-bcpocus' 'Reg-nephropocus'\n",
      " 'pneu-everyday' 'pneu-gred-6' 'pneu-gred-7' 'pneu-radiopaeda']\n",
      "test ['Cov-Butterfly-COVID Lung 1' 'Cov-MSU-SkipLesions' 'Pneu-Atlas-pneumonia'\n",
      " 'Pneu-grep-pneumonia4' 'Reg-Butterfly']\n",
      "45\n",
      "-------------- SPLIT  2 -------------------\n",
      "train ['Cov-Atlas+(44)' 'Cov-Atlas+(45)' 'Cov-Atlas-+(43)' 'Cov-Atlas-Day+1'\n",
      " 'Cov-Atlas-Day+2' 'Cov-Atlas-Day+3' 'Cov-Atlas-Day+4'\n",
      " 'Cov-B_ConvexProb_score1' 'Cov-Butterfly-COVID Lung 1'\n",
      " 'Cov-Butterfly-COVID Skip Lesion' 'Cov-C_ConvexProb_score3'\n",
      " 'Cov-C_Convex_Prob_score2' 'Cov-D_Convex_Prob_score3'\n",
      " 'Cov-MSU-SkipLesions' 'Cov-clarius' 'Cov-grepmed-blines-pocus-'\n",
      " 'Cov-grepmed2' 'Cov-grepmed3' 'Pneu-Atlas-pneumonia'\n",
      " 'Pneu-Atlas-pneumonia-AirBronch' 'Pneu-Atlas-pneumonia2'\n",
      " 'Pneu-grep-pneumonia1' 'Pneu-grep-pneumonia2' 'Pneu-grep-pneumonia4'\n",
      " 'Reg-Atlas' 'Reg-Atlas-alines' 'Reg-Atlas-lungcurtain' 'Reg-Butterfly'\n",
      " 'Reg-Grep-Normal' 'Reg-Youtube' 'Reg-Youtube-Video_902_Lung_POCUS'\n",
      " 'Reg-Youtube_Video_29_Lung_POCUS_left'\n",
      " 'Reg-Youtube_Video_29_Lung_POCUS_right' 'Reg-bcpocus' 'Reg-nephropocus'\n",
      " 'pneu-gred-6' 'pneu-radiopaeda']\n",
      "test ['Cov-Butterfly-COVID Lung 2' 'Cov-MSU-COVID Lung 2-Blines'\n",
      " 'Pneu-grep-pneumonia3' 'Reg-Grep-Alines' 'Reg-NormalLungs'\n",
      " 'Reg-Youtube-Video_902_Lung_POCUS-left' 'pneu-everyday' 'pneu-gred-7']\n",
      "45\n",
      "-------------- SPLIT  3 -------------------\n",
      "train ['Cov-Atlas+(44)' 'Cov-Atlas+(45)' 'Cov-Atlas-+(43)' 'Cov-Atlas-Day+1'\n",
      " 'Cov-Atlas-Day+2' 'Cov-Atlas-Day+3' 'Cov-Atlas-Day+4'\n",
      " 'Cov-B_ConvexProb_score1' 'Cov-Butterfly-COVID Lung 1'\n",
      " 'Cov-Butterfly-COVID Lung 2' 'Cov-C_ConvexProb_score3'\n",
      " 'Cov-C_Convex_Prob_score2' 'Cov-D_Convex_Prob_score3'\n",
      " 'Cov-MSU-COVID Lung 2-Blines' 'Cov-MSU-SkipLesions' 'Cov-clarius'\n",
      " 'Cov-grepmed-blines-pocus-' 'Cov-grepmed2' 'Cov-grepmed3'\n",
      " 'Pneu-Atlas-pneumonia' 'Pneu-Atlas-pneumonia-AirBronch'\n",
      " 'Pneu-Atlas-pneumonia2' 'Pneu-grep-pneumonia2' 'Pneu-grep-pneumonia3'\n",
      " 'Pneu-grep-pneumonia4' 'Reg-Atlas' 'Reg-Atlas-alines'\n",
      " 'Reg-Atlas-lungcurtain' 'Reg-Butterfly' 'Reg-Grep-Alines'\n",
      " 'Reg-Grep-Normal' 'Reg-NormalLungs' 'Reg-Youtube'\n",
      " 'Reg-Youtube-Video_902_Lung_POCUS-left'\n",
      " 'Reg-Youtube_Video_29_Lung_POCUS_left' 'Reg-bcpocus' 'pneu-everyday'\n",
      " 'pneu-gred-7' 'pneu-radiopaeda']\n",
      "test ['Cov-Butterfly-COVID Skip Lesion' 'Pneu-grep-pneumonia1'\n",
      " 'Reg-Youtube-Video_902_Lung_POCUS'\n",
      " 'Reg-Youtube_Video_29_Lung_POCUS_right' 'Reg-nephropocus' 'pneu-gred-6']\n",
      "45\n",
      "-------------- SPLIT  4 -------------------\n",
      "train ['Cov-Atlas+(44)' 'Cov-Atlas+(45)' 'Cov-Atlas-+(43)' 'Cov-Atlas-Day+1'\n",
      " 'Cov-Atlas-Day+2' 'Cov-Atlas-Day+3' 'Cov-Atlas-Day+4'\n",
      " 'Cov-B_ConvexProb_score1' 'Cov-Butterfly-COVID Lung 1'\n",
      " 'Cov-Butterfly-COVID Lung 2' 'Cov-Butterfly-COVID Skip Lesion'\n",
      " 'Cov-C_ConvexProb_score3' 'Cov-C_Convex_Prob_score2'\n",
      " 'Cov-D_Convex_Prob_score3' 'Cov-MSU-COVID Lung 2-Blines'\n",
      " 'Cov-MSU-SkipLesions' 'Pneu-Atlas-pneumonia' 'Pneu-grep-pneumonia1'\n",
      " 'Pneu-grep-pneumonia2' 'Pneu-grep-pneumonia3' 'Pneu-grep-pneumonia4'\n",
      " 'Reg-Atlas' 'Reg-Atlas-alines' 'Reg-Atlas-lungcurtain' 'Reg-Butterfly'\n",
      " 'Reg-Grep-Alines' 'Reg-NormalLungs' 'Reg-Youtube'\n",
      " 'Reg-Youtube-Video_902_Lung_POCUS'\n",
      " 'Reg-Youtube-Video_902_Lung_POCUS-left'\n",
      " 'Reg-Youtube_Video_29_Lung_POCUS_right' 'Reg-nephropocus' 'pneu-everyday'\n",
      " 'pneu-gred-6' 'pneu-gred-7']\n",
      "test ['Cov-clarius' 'Cov-grepmed-blines-pocus-' 'Cov-grepmed2' 'Cov-grepmed3'\n",
      " 'Pneu-Atlas-pneumonia-AirBronch' 'Pneu-Atlas-pneumonia2'\n",
      " 'Reg-Grep-Normal' 'Reg-Youtube_Video_29_Lung_POCUS_left' 'Reg-bcpocus'\n",
      " 'pneu-radiopaeda']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# For the pocus-splitted data\n",
    "\n",
    "# MAIN LOOP FOR CROSS VAL\n",
    "for split in range(SPLIT):\n",
    "    print(\"-------------- SPLIT \", split, \"-------------------\")\n",
    "    \n",
    "    train_labels, test_labels, test_files = [], [], []\n",
    "    train_data, test_data = [], []\n",
    "\n",
    "    # loop over split0, split1 etc\n",
    "    for imagePath in paths.list_images(CROSS_VAL_DIR):\n",
    "        \n",
    "        path_parts = imagePath.split(os.path.sep)\n",
    "        # extract the split\n",
    "        train_test = path_parts[-3][-1]\n",
    "        # extract the class label from the filename\n",
    "        label = path_parts[-2]\n",
    "        \n",
    "        # load the image, swap color channels, and resize it to be a fixed\n",
    "        # 224x224 pixels while ignoring aspect ratio\n",
    "        # image = cv2.imread(imagePath)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # image = cv2.resize(image, (224, 224))\n",
    "        # TESTING\n",
    "        image = (imagePath.split(os.path.sep)[-1]).split(\".\")[0]\n",
    "        \n",
    "        # update the data and labels lists, respectively\n",
    "        if train_test == str(split):\n",
    "            test_labels.append(label)\n",
    "            test_data.append(image)\n",
    "            test_files.append(imagePath.split(os.path.sep)[-1])\n",
    "        else:\n",
    "            train_labels.append(label)\n",
    "            train_data.append(image)\n",
    "    \n",
    "    # Test printouts\n",
    "    print(\"train\", np.unique(train_data))\n",
    "    print(\"test\", np.unique(test_data))\n",
    "    assert len(set(np.unique(train_data)).intersection(set(np.unique(test_data)))) == 0, \"intersection train test nonempty\"\n",
    "    print(len(np.unique(train_data))+ len(np.unique(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for covid paper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_in_path = \"../data_pocus/cross_validation_data\"\n",
    "txt_out_path = \"../data_pocus/cross_val_txt\"\n",
    "name_mapping = {\"covid\":\"COVID-19\", \"pneunomia\":\"pneumonia\", \"regular\":\"normal\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_ind in range(SPLIT):\n",
    "    # test_data = paths.list_images(os.path.join(txt_in_path, \"split\"+str(split_ind)))\n",
    "    train_data, test_data = [], []\n",
    "    for iter_fold in range(SPLIT):\n",
    "        if iter_fold==split_ind:\n",
    "            test_data.extend(paths.list_images(os.path.join(txt_in_path, \"split\"+str(split_ind))))\n",
    "        else:\n",
    "            train_data.extend(paths.list_images(os.path.join(txt_in_path, \"split\"+str(iter_fold))))\n",
    "\n",
    "    train_test_data = {\"train\": train_data, \"test\": test_data}\n",
    "\n",
    "    for traintest in [\"train\", \"test\"]:\n",
    "        out_test_file = os.path.join(txt_out_path, \"fold_\"+str(split_ind)+\"_\"+traintest+\".txt\")\n",
    "        with open(out_test_file, 'a') as outfile:\n",
    "            for line in train_test_data[traintest]:\n",
    "                parts = line.split(\"/\")\n",
    "                vid_name = parts[-1].split(\".\")[0]\n",
    "                if \" \" in vid_name:\n",
    "                    vid_name = vid_name.replace(\" \", \"_\")\n",
    "                    # print(vid_name)\n",
    "                label = name_mapping[parts[-2]]\n",
    "                out_line = \"\\t\".join([vid_name, line, label])\n",
    "                # print(vid_name, line, label)\n",
    "                outfile.write(out_line+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to write framerates etc to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = \"../data_pocus/cleaned_data_videos.nosync\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some filename where to write the data\n",
    "out_file_path = \"vid_info.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open(out_file_path, \"w\")\n",
    "out_file.write(\"Filename,Framerate,Resolution,Number of frames\\n\")\n",
    "vid_files = os.listdir(video_dir)\n",
    "\n",
    "for i in range(len(vid_files)):\n",
    "    \n",
    "    # skip unnecessary files\n",
    "    if vid_files[i][0]==\".\":\n",
    "        # DStore etc\n",
    "        continue\n",
    "    \n",
    "    # define video path\n",
    "    # print(\"video\", vid_files[i], \"number \",i, \"out of \", len(vid_files))\n",
    "    video_path = os.path.join(video_dir, vid_files[i])\n",
    "    \n",
    "    # determine label\n",
    "    if vid_files[i][:3]==\"Cov\":\n",
    "        label = \"covid\"\n",
    "    elif vid_files[i][:3]==\"Pne\" or vid_files[i][:3]==\"pne\":\n",
    "        label = \"pneunomia\"\n",
    "    elif vid_files[i][:3]==\"Reg\":\n",
    "        label = \"regular\"\n",
    "    else:\n",
    "        raise ValueError(\"Wrong label! \"+ vid_files[i])\n",
    "    out_path = os.path.join(out_image_dir, label)\n",
    "    \n",
    "    # copy if image\n",
    "    if vid_files[i][-3:]==\"jpg\" or vid_files[i][-3:]==\"png\":\n",
    "        shutil.copy(video_path, out_path)\n",
    "        continue\n",
    "    \n",
    "    # read and write if video\n",
    "    cap = cv2.VideoCapture(video_path)   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    every_x_image = int(frameRate/FRAMERATE)\n",
    "    print(vid_files[i], \"framerate\", cap.get(5),\"width\", cap.get(3), \"height\", cap.get(4), \"number frames:\", cap.get(7))\n",
    "    out_str = vid_files[i]+\",\"+str(int(cap.get(5)))+\",\"+str(int(cap.get(3)))+\"x\"+str(int(cap.get(4)))+\",\"+str(int(cap.get(7)))+\"\\n\"\n",
    "    print(out_str)\n",
    "    out_file.write(out_str)\n",
    "    cap.release()\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge framerate csv and previous data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prev_data = pd.read_csv(\"pocus_covid_data\")\n",
    "new_data = pd.read_csv(\"vid_info.csv\")\n",
    "# prev_data = prev_data.drop(columns=[\"Frame rate\", \"Image / Frame resolution\", \"Number of frames\"])\n",
    "# JOIN both dataframes\n",
    "both = pd.merge(prev_data, new_data, on=\"Filename\", how=\"outer\")\n",
    "# save as joint csv\n",
    "both.to_csv(\"merged_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
